{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1nQu-uH7-uT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers, callbacks\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import legacy as legacy_optimizers\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "from keras.optimizers import Adam\n",
        "import zipfile\n",
        "from google.colab import drive\n",
        "from tensorflow.keras.regularizers import l2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TlJwmInh8H15"
      },
      "outputs": [],
      "source": [
        "def plot_model_history(model_history):\n",
        "    fig, axs = plt.subplots(1,2,figsize=(15,5))\n",
        "    \n",
        "    axs[0].plot(range(1,len(model_history.history['accuracy'])+1),model_history.history['accuracy'])\n",
        "    axs[0].plot(range(1,len(model_history.history['val_accuracy'])+1),model_history.history['val_accuracy'])\n",
        "    axs[0].set_title('Model Accuracy')\n",
        "    axs[0].set_ylabel('Accuracy')\n",
        "    axs[0].set_xlabel('Epoch')\n",
        "    axs[0].set_xticks(np.arange(1, len(model_history.history['accuracy'])+1, len(model_history.history['accuracy'])//10))\n",
        "    axs[0].legend(['train', 'val'], loc='best')\n",
        "    \n",
        "    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n",
        "    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n",
        "    axs[1].set_title('Model Loss')\n",
        "    axs[1].set_ylabel('Loss')\n",
        "    axs[1].set_xlabel('Epoch')\n",
        "    axs[1].set_xticks(np.arange(1, len(model_history.history['loss'])+1, len(model_history.history['loss'])//10))\n",
        "    axs[1].legend(['train', 'val'], loc='best')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6cc9L2038dws"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PGjMgAps8eHK"
      },
      "outputs": [],
      "source": [
        "base_skin_dir = os.path.join('/content/drive/MyDrive', 'skin_disease_dataset')\n",
        "\n",
        "# Merging images from both datsets in two folders\n",
        "imageid_path_dict = {os.path.splitext(os.path.basename(x))[0]: x\n",
        "                     for x in glob(os.path.join(base_skin_dir, '*', '*.jpg'))}\n",
        "\n",
        "lesion_type_dict = {\n",
        "    'nv': 'Melanocytic nevi',\n",
        "    'mel': 'Melanoma',\n",
        "    'bkl': 'Benign keratosis-like lesions ',\n",
        "    'bcc': 'Basal cell carcinoma',\n",
        "    'akiec': 'Actinic keratoses',\n",
        "    'vasc': 'Vascular lesions',\n",
        "    'df': 'Dermatofibroma'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SS2rGvEo8eJV"
      },
      "outputs": [],
      "source": [
        "skin_df = pd.read_csv(os.path.join(base_skin_dir, 'HAM10000_metadata.csv'))\n",
        "\n",
        "skin_df['path'] = skin_df['image_id'].map(imageid_path_dict.get)\n",
        "skin_df['cell_type'] = skin_df['dx'].map(lesion_type_dict.get) \n",
        "skin_df['cell_type_idx'] = pd.Categorical(skin_df['cell_type']).codes\n",
        "\n",
        "skin_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mkALvc1Y8eLr"
      },
      "outputs": [],
      "source": [
        "skin_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q7wtZu0M8eNk"
      },
      "outputs": [],
      "source": [
        "skin_df['age'].fillna((skin_df['age'].mean()), inplace=True)\n",
        "skin_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K1fLLWUH8ePN"
      },
      "outputs": [],
      "source": [
        "print(skin_df.dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_2jsNSvsYuF"
      },
      "outputs": [],
      "source": [
        "fig, ax1 = plt.subplots(1, 1, figsize= (10, 5))\n",
        "colors = ['r', 'g', 'b', 'c', 'm', 'y', 'k']\n",
        "skin_df['cell_type'].value_counts().plot(kind='bar', ax=ax1, color=colors)\n",
        "ax1.set_xlabel('Cell Type')\n",
        "ax1.set_ylabel('Count')\n",
        "ax1.set_title('Distribution of Cell Types')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "voIWX3P_slC9"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8,6))\n",
        "skin_df['dx_type'].value_counts().plot(kind='bar', color=['r', 'g', 'b', 'c', 'm'])\n",
        "plt.xlabel('Diagnosis Type')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Distribution of Diagnosis Types')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJK-OBxbtS71"
      },
      "outputs": [],
      "source": [
        "fig, ax1 = plt.subplots(1, 1, figsize=(10, 5))\n",
        "sns.countplot(data=skin_df, x='localization', ax=ax1, palette='viridis')\n",
        "ax1.set_xlabel('Localization')\n",
        "ax1.set_ylabel('Count')\n",
        "ax1.set_title('Distribution of Lesion Localizations')\n",
        "ax1.tick_params(axis='x', rotation=90)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eCjvbCqntWxk"
      },
      "outputs": [],
      "source": [
        "fig, ax1 = plt.subplots(1, 1, figsize=(10, 5))\n",
        "sns.histplot(data=skin_df, x='age', kde=True, stat='density', ax=ax1, color='purple')\n",
        "ax1.set_xlabel('Age')\n",
        "ax1.set_ylabel('Density')\n",
        "ax1.set_title('Age Distribution')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ItEkJ9s3tWpk"
      },
      "outputs": [],
      "source": [
        "fig, ax1 = plt.subplots(1, 1, figsize= (10, 5))\n",
        "sns.countplot(data=skin_df, x='sex', ax=ax1, palette='mako')\n",
        "ax1.set_xlabel('Sex')\n",
        "ax1.set_ylabel('Count')\n",
        "ax1.set_title('Distribution of Patient Gender')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNGMr5TTsktt"
      },
      "outputs": [],
      "source": [
        "sns.scatterplot(x='age', y='cell_type_idx', hue='cell_type', data=skin_df)\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QMxy-o8w8eQ8"
      },
      "outputs": [],
      "source": [
        "# Define a function to read and resize images\n",
        "def read_image(filepath, size):\n",
        "    return np.asarray(Image.open(filepath).resize(size))\n",
        "\n",
        "# Use the function to create a new 'image' column in the dataframe\n",
        "skin_df['image'] = skin_df['path'].apply(lambda x: read_image(x, (100, 75)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-zz4SpK8eS2"
      },
      "outputs": [],
      "source": [
        "n_samples = 5\n",
        "fig, m_axs = plt.subplots(7, n_samples, figsize = (4*n_samples, 3*7))\n",
        "for ax_row, (type_name, type_rows) in zip(m_axs, skin_df.sort_values(['cell_type']).groupby('cell_type')):\n",
        "    ax_row[0].set_title(type_name)\n",
        "    for c_ax, (_, c_row) in zip(ax_row, type_rows.sample(n_samples, random_state=1234).iterrows()):\n",
        "        c_ax.imshow(c_row['image'])\n",
        "        c_ax.axis('off')\n",
        "plt.suptitle('Sample Images for Each Cell Type', fontsize=20)\n",
        "plt.tight_layout()\n",
        "plt.subplots_adjust(top=0.9)\n",
        "fig.savefig('category_samples.png', dpi=300)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3HN014qU_Fce"
      },
      "outputs": [],
      "source": [
        "skin_df['image'].map(lambda x: x.shape).value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yLGEF0rl_FnF"
      },
      "outputs": [],
      "source": [
        "features=skin_df.drop(columns=['cell_type_idx'],axis=1)\n",
        "target=skin_df['cell_type_idx']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54iQTppv_Fqz"
      },
      "outputs": [],
      "source": [
        "x_train_o, x_test_o, y_train_o, y_test_o = train_test_split(features, target, test_size=0.20,random_state=1234)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vlLumN1x_FtU"
      },
      "outputs": [],
      "source": [
        "# Split data into train and test sets\n",
        "x_train_o, x_test, y_train_o, y_test = train_test_split(features, target, test_size=0.20, random_state=1234)\n",
        "\n",
        "# Split train set into train and validation sets\n",
        "x_train, x_validate, y_train, y_validate = train_test_split(x_train_o, y_train_o, test_size=0.25, random_state=1234)\n",
        "\n",
        "# Print the shapes of the resulting sets\n",
        "print(\"Train set shape: \", x_train.shape, y_train.shape)\n",
        "print(\"Validation set shape: \", x_validate.shape, y_validate.shape)\n",
        "print(\"Test set shape: \", x_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9lCKGkQ9_Vn0"
      },
      "outputs": [],
      "source": [
        "x_train = np.asarray(x_train_o['image'].tolist())\n",
        "x_test = np.asarray(x_test_o['image'].tolist())\n",
        "\n",
        "x_train_mean = np.mean(x_train)\n",
        "x_train_std = np.std(x_train)\n",
        "\n",
        "x_test_mean = np.mean(x_test)\n",
        "x_test_std = np.std(x_test)\n",
        "\n",
        "x_train = (x_train - x_train_mean)/x_train_std\n",
        "x_test = (x_test - x_test_mean)/x_test_std"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54kV1Nyo_Vyz"
      },
      "outputs": [],
      "source": [
        "# Perform one-hot encoding on the labels\n",
        "y_train = to_categorical(y_train_o, num_classes = 7)\n",
        "y_test = to_categorical(y_test_o, num_classes = 7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9PSOuUj_V1T"
      },
      "outputs": [],
      "source": [
        "x_train, x_validate, y_train, y_validate = train_test_split(x_train, y_train, test_size = 0.1, random_state = 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GBLtRK0t_V3l"
      },
      "outputs": [],
      "source": [
        "# Reshape image in 3 dimensions (height = 75px, width = 100px , canal = 3)\n",
        "x_train = x_train.reshape(x_train.shape[0], *(75, 100, 3))\n",
        "x_test = x_test.reshape(x_test.shape[0], *(75, 100, 3))\n",
        "x_validate = x_validate.reshape(x_validate.shape[0], *(75, 100, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93a45QHYNYQi"
      },
      "outputs": [],
      "source": [
        "input_shape = (75, 100, 3)\n",
        "num_classes = 7\n",
        "l2_regularizer = l2(0.001)\n",
        "batch_size = 16\n",
        "epochs = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQZXIWED_V6M"
      },
      "outputs": [],
      "source": [
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.Conv2D(64, (3, 3), padding='same', input_shape=input_shape, kernel_regularizer=l2_regularizer))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Activation('relu'))\n",
        "model.add(layers.Conv2D(64, (3, 3), padding='same', kernel_regularizer=l2_regularizer))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Activation('relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Dropout(0.25))\n",
        "\n",
        "model.add(layers.Conv2D(128, (3, 3), padding='same', kernel_regularizer=l2_regularizer))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Activation('relu'))\n",
        "model.add(layers.Conv2D(128, (3, 3), padding='same', kernel_regularizer=l2_regularizer))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Activation('relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Dropout(0.25))\n",
        "\n",
        "model.add(layers.Conv2D(256, (3, 3), padding='same', kernel_regularizer=l2_regularizer))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Activation('relu'))\n",
        "model.add(layers.Conv2D(256, (3, 3), padding='same', kernel_regularizer=l2_regularizer))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Activation('relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Dropout(0.25))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(512, kernel_regularizer=l2_regularizer))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Activation('relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(num_classes, activation='softmax'))\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3FB9EDX_kIb"
      },
      "outputs": [],
      "source": [
        "optimizer = Adam(lr=0.0001)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-kN8pPr_kQL"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ME_zhkJ_rLU"
      },
      "outputs": [],
      "source": [
        "# Set a learning rate annealer\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc',\n",
        "                                            patience=3,\n",
        "                                            verbose=1,\n",
        "                                            factor=0.5,\n",
        "                                            min_lr=0.00001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qLvbwVG_0hE"
      },
      "outputs": [],
      "source": [
        "# With data augmentation to prevent overfitting\n",
        "datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,\n",
        "        samplewise_center=False,\n",
        "        featurewise_std_normalization=False,\n",
        "        samplewise_std_normalization=False,\n",
        "        zca_whitening=False,\n",
        "        rotation_range=10,\n",
        "        zoom_range=0.1,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=True,\n",
        "        brightness_range=(0.9, 1.1),\n",
        "        fill_mode='nearest')\n",
        "\n",
        "datagen.fit(x_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PobteVZC_51s"
      },
      "outputs": [],
      "source": [
        "# Fit the model\n",
        "history = model.fit(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                    epochs=epochs, validation_data=(x_validate, y_validate),\n",
        "                    verbose=1, steps_per_epoch=x_train.shape[0] \n",
        "                    callbacks=[learning_rate_reduction])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFSpRU42N3Q1"
      },
      "outputs": [],
      "source": [
        "loss, accuracy = model.evaluate(x_test, y_test, verbose=1)\n",
        "loss_v, accuracy_v = model.evaluate(x_validate, y_validate, verbose=1)\n",
        "print(\"Validation: accuracy = %f  ;  loss_v = %f\" % (accuracy_v, loss_v))\n",
        "print(\"Test: accuracy = %f  ;  loss = %f\" % (accuracy, loss))\n",
        "model.save('/content/drive/MyDrive/neww_dr_skin_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TCE4GyCTPQG9"
      },
      "outputs": [],
      "source": [
        "plot_model_history(history)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
